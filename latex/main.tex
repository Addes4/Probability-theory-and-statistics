\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[swedish]{babel}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{siunitx}
\usepackage{titlesec}
\usepackage{float}  % Gör så att [H] fungerar
\usepackage{caption}
\usepackage{multido}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{booktabs}

\newcommand{\TabRow}[2]{#1 & #2 \\ \hline}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\E}{\operatorname{E}}

\setlength{\parindent}{0pt}            % Sätter indrag (parindent) för nya stycken till 0 → ingen indragning

\makeatletter
\let\origclearpage\clearpage           % Sparar originalkommandot \clearpage i \origclearpage
\makeatother

\newcommand{\NoChapterPageBreaks}{\let\clearpage\relax}       
% Skapar ett nytt kommando som tar bort sidbrytningar vid kapitel
% (ersätter \clearpage med tomt kommando \relax)

\newcommand{\RestoreChapterPageBreaks}{\let\clearpage\origclearpage}
% Skapar ett nytt kommando som återställer originalbeteendet för sidbrytningar vid kapitel

\geometry{margin=1in}                  % Sätter sidmarginaler till 1 tum runt hela sidan
\raggedbottom                          % Hindrar LaTeX från att stretcha texten vertikalt för att fylla sidan

\addto\captionsenglish{\renewcommand{\chaptername}{}}

\titleformat{\chapter}[block]
  {\normalfont\huge\bfseries}
  {\thechapter\quad}
  {0pt}
  {}
\titlespacing*{\chapter}{0pt}{-20pt}{20pt}


\begin{document}

\chapter*{Problem 3: Linjär regression}

Linjär regression är en metod för att modellera sambandet mellan en beroende 
variabel $y$ och en eller flera oberoende variabler $x$ genom en linjär funktion. 
Grundidén är att hitta den linje som bäst passar data genom att minimera summan 
av kvadrerade fel.

För enkel linjär regression har vi modellen:
\begin{equation}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \quad i = 1, 2, \ldots, n
\end{equation}
där $\beta_0$ är intercept, $\beta_1$ är lutningen, och $\varepsilon_i$ är feltermer 
som antas vara oberoende och normalfördelade med väntevärde 0 och varians $\sigma^2$.

Minsta kvadratmetoden minimerar objektfunktionen:
\begin{equation}
Q(\beta_0, \beta_1) = \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2
\end{equation}

Genom att sätta partialderivatorna lika med noll får vi normalekvationerna, vilka kan lösas analytiskt för att ge skattningarna $\hat{\beta_0}$ och $\hat{\beta_1}$.

I vektorform kan modellen skrivas som:
\begin{equation}
\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon}
\end{equation}
där $\mathbf{X}$ är designmatrisen, $\boldsymbol{\beta}$ är parametervektorn, och lösningen blir:
\begin{equation}
\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}
\end{equation}

\subsection*{Funktionen tools.regress}

Filen \texttt{tools.py} innehåller funktionen \texttt{regress} som implementerar multipel linjär regression med minsta kvadratmetoden. Funktionen löser modellen:

\begin{equation}
\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon}
\end{equation}

där $\mathbf{y}$ är en vektor av observerade värden med form $(n,)$, $\mathbf{X}$ är en matris av regressorer med form $(n, p)$, $\boldsymbol{\beta}$ är parametervektorn med form $(p,)$, och $\boldsymbol{\varepsilon}$ är en vektor av slumpmässiga fel med form $(n,)$.

Funktionen regress har följande egenskaper:

\begin{enumerate}
\item \textbf{QR-faktorisering:} Funktionen använder QR-faktorisering (np.linalg.qr) för att lösa normalekvationerna numeriskt stabilt, istället för att direkt invertera $\mathbf{X}^T\mathbf{X}$.

\item \textbf{NaN-hantering:} Alla rader som innehåller NaN-värden i antingen $\mathbf{X}$ eller $\mathbf{y}$ filtreras bort innan beräkningarna.

\item \textbf{Konfidensintervall:} Funktionen beräknar konfidensintervall för varje parameter baserat på t-fördelningen med $n-p$ frihetsgrader, där $n$ är antalet observationer och $p$ är antalet parametrar.

\item \textbf{Standardfel:} Standardfelet för varje parameter beräknas från diagonalen av $(\mathbf{R}^T\mathbf{R})^{-1}$, där $\mathbf{R}$ kommer från QR-faktoriseringen.
\end{enumerate}

\end{document}